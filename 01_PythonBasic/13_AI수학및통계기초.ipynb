{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. AI수학및통계기초\n",
    "### (선형대수, 미적분, 확률과통계, 최적화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='image/tensor.png', width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 선형대수 기초\n",
    "# Scalar - 하나의 수(single number)를 의미 / ex) 3.14, -7\n",
    "# Vector - 크기와 방향을 가진 수 / ex (2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Malgun Gothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 벡터 시각화\n",
    "# 새로운 Figure(그래프 캔버스)를 생성\n",
    "plt.figure()\n",
    "\n",
    "# quiver 는 벡터(화살표)를 그려주는 함수\n",
    "# 시작점: (0, 0), 끝점: (2, 3)\n",
    "# angles='xy' 는 벡터의 방향을 x, y 좌표계 기준으로 맞추겠다는 의미\n",
    "# scale_units='xy'는 길이 단위를 좌표계 단위로 설정\n",
    "# scale=1 은 벡터 길이를 축소/확대하지 않겠다는 의미\n",
    "# color='blue' 는 벡터의 색상을 파란색으로 설정\n",
    "plt.quiver(0, 0, 2, 3, angles='xy', scale_units='xy', scale=1, color='blue')\n",
    "\n",
    "# xlim(a, b), ylim(a, b) - 축 범위를 a부터 b까지 지정\n",
    "plt.xlim(0,4)\n",
    "plt.ylim(0,4)\n",
    "\n",
    "# 축의 비율을 동일하게 설정 (벡터의 기울기 시각적 왜곡 방지)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()\n",
    "plt.title(\"벡터 예시: (2, 3)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Malgun Gothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "B = np.array([[5, 6],\n",
    "              [7, 8]])\n",
    "\n",
    "# 행렬 덧셈\n",
    "# - 두 이미지의 픽셀값을 더하거나, 뉴럴넷의 활성값에 편상을 더할 때 사용됨\n",
    "add_result = A + B\n",
    "print(\"A + B =\")\n",
    "print(f\"{add_result}\\n\")\n",
    "\n",
    "# 행렬 곱셈\n",
    "# - 입력 데이터와 가중치의 곱 (딥러닝)\n",
    "dot_result = np.dot(A, B)\n",
    "print(\"A dot B =\")\n",
    "print(dot_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Malgun Gothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 단위행렬 생성\n",
    "# - 항등원 역할: 어떤 행렬 A에 대해 A * I = A, I * A = A (숫자 1 처럼 작용)\n",
    "#                A에 단위 행렬을 곱해도 값이 그대로 유지되는 것\n",
    "I = np.eye(3)\n",
    "print(\"단위행렬 3x3 :\")\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Malgun Gothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 전치행렬 (Transpose)\n",
    "# = 행 기준 데이터를 열 기준으로 바꾸어 처리 (e.g., 벡터 내적에서 많이 사용)\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "print(\"A.T =\")\n",
    "print(A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Malgun Gothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 역행렬\n",
    "# - 행렬 방정식 AX = B 를 풀 때 ( X = A^1 * B 와 같은 방식으로 해 구함)\n",
    "A = np.array([[4, 7], [2, 6]])\n",
    "inv_A = np.linalg.inv(A)\n",
    "print(\"역행렬 A^-1 =\")\n",
    "print(f\"{inv_A}\\n\")\n",
    "print(\"A * A^-1 =\")\n",
    "print(np.dot(A, inv_A))\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='image/inv.gif', width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 선형대수 응용\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 미분 기초\n",
    "# 함수(Function) - 입력값에 대해 하나의 출력값을 대응시키는 규칙\n",
    "# 극한(Limit) - 어떤 값 x에 가까워질 때 함수값이 수렴하는 값을 의미\n",
    "# 미분(Derivative) - 함수의 순간 변화율 또는 기울기를 나타내며, 도함수라고도 함\n",
    "#                    기하학적으로는 곡선의 접선의 기울기임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Malgun Gothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 함수 정의\n",
    "x = np.linspace(-2, 2, 100)\n",
    "y = x**2\n",
    "dy = 2 * x # 도함수\n",
    "\n",
    "plt.plot(x, y, label=\"y = 2**2\")\n",
    "plt.plot(x, dy, label=\"y' = 2x\", linestyle='--')\n",
    "plt.title(\"함수와 도함수 시각화\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 적분 기초\n",
    "# 극댓값과 극솟값 (최댓값/최솟값) - 도함수가 0이 되는 지점에서 극댓값 또는 극솟값이 존재할 수 있음\n",
    "#                                   ex) f(x) = -x² + 4x 의 극댓값은 도함수 f'(x) = -2x + 4 = 0 → x = 2 \n",
    "\n",
    "# 적분의 개념과 면적 - 적분은 함수 아래의 면적을 계산하는 연산\n",
    "#                      정적분 ∫₀² x² dx = [⅓x³]₀² = 8/3\n",
    "\n",
    "# 경사하강법의 원리 - 경사하강법은 함수의 최소값을 찾기 위한 최적화 알고리즘임\n",
    "#                     함수의 기울기(도함수)를 반영하여 점진적으로 최솟값에 접근함\n",
    "#                     업데이트 공식: x = x - η * f'(x) (η는 학습률) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Malgun Gothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 함수 및 면적 계산 \n",
    "x = np.linspace(0, 2, 100) \n",
    "y = x**2 \n",
    "\n",
    "plt.plot(x, y, label='y = x²') \n",
    "plt.fill_between(x, y, alpha=0.3, label='면적 (적분)') \n",
    "plt.title(\"적분을 통한 면적 계산\") \n",
    "plt.legend() \n",
    "plt.grid(True) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 확률과 통계 기초\n",
    "# 확률의 정의 - 확률은 어떤 사건이 일어날 가능성을 수치로 나타낸 것\n",
    "#               ex) 동전 앞면이 나올 확률은 0.5\n",
    "\n",
    "# 조건부 확률 - 어떤 사건이 이미 발생했을 때, 다른 사건이 일어날 확률\n",
    "#               P(A|B) = P(A∩B)/P(B)\n",
    "\n",
    "# 평균과 분산 - 평균은 자료의 중심값, 분산은 평균으로부터의 퍼짐 정도를 나타냄\n",
    "#               분산 = E[(X - μ)²], 표준편차 = √분산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Malgun Gothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 정규분포 곡선 \n",
    "x = np.linspace(-4, 4, 1000) \n",
    "y = 1 / (np.sqrt(2 * np.pi)) * np.exp(-x**2 / 2)\n",
    "\n",
    "plt.plot(x, y, label=\"표준 정규분포\", color=\"green\") \n",
    "plt.fill_between(x, y, where=(x > -1) & (x < 1), alpha=0.3, color=\"green\", \n",
    "label=\"평균±1표준편차\")\n",
    "# where: 조건을 만족할 때만 채우기\n",
    "plt.title(\"정규분포 시각화\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 확률과 통계 심화\n",
    "# 확률변수 - 확률변수는 확률적으로 결정되는 값을 의미함\n",
    "#            ex) 이산형(주사위, ...), 연속형(키, 무게, ...)으로 나뉨\n",
    "\n",
    "# 기대값 - 기대값은 확률변수의 평균적인 값\n",
    "#          E[X] = Σ x * P(x) \n",
    "\n",
    "# 샘플링 - 전체 모집단에서 표본을 추출하는 행위, 무작위 샘플링은 통계적 일반화에 필수\n",
    "\n",
    "# 베이즈 정리 - 조건부 확률의 계산을 돕는 수식\n",
    "#               관측된 데이터를 기반으로 사후 확률을 추론할 수 있게 해주는 공식. \n",
    "#               머신러닝, 의료 진단, 자연어 처리 등 수많은 분야에 사용됨\n",
    "\n",
    "# P(스팸) = 0.2, P(단어=\"당첨\"|스팸) = 0.9, P(단어=\"당첨\") = 0.3\n",
    "# P(스팸|단어=\"당첨\") = ?\n",
    "P_spam = 0.2 # P(A)\n",
    "P_win_given_spam = 0.9 # #P(B|A)\n",
    "P_win = 0.3 # P(B)\n",
    "P_spam_given_win = (P_win_given_spam * P_spam) / P_win \n",
    "print(f\"P(스팸|당첨): {P_spam_given_win:.2f}\") \n",
    "\n",
    "# 머신러닝과의 연계 - 스팸 필터, 분류기 등은 베이즈 정리를 활용한 확률적 모델을 사용\n",
    "#                     ex) Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 최적화 기초\n",
    "# 함수의 최소화 개념 - 최적화 문제는 일반적으로 함수의 최소값(또는 최대값)을 찾는 것\n",
    "#                      ex) f(x) = x² 의 최소값은 x = 0 에서 발생\n",
    "\n",
    "# 경사하강법 알고리즘 - 경사하강법은 함수의 기울기를 이용해 최소값을 찾는 반복 알고리즘\n",
    "#                       업데이트 공식: x = x - η * f'(x) (η는 학습률)\n",
    "\n",
    "# 학습률의 영향 - 학습률이 너무 크면 발산하고, 너무 작으면 수렴 속도가 느림, 적절한 값 조절이 중요\n",
    "\n",
    "# 기본 옵티마이저 개요 - SGD, Momentum, Adam 등의 알고리즘은 경사하강법을 개선한 다양한 방법\n",
    "# - SGD: 단순 경사하강법\n",
    "# - Momentum: 관성 추가\n",
    "# - Adam: 적응적 학습률 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 최적화 응용\n",
    "# 손실 함수 개념 - 손실 함수는 모델 예측값과 실제값 사이의 오차를 수치화한 함수\n",
    "# 로컬 최소값 - 현재 지점 주변에서는 가장 낮지만, 전체 범위에서는 더 낮은 값이 존재함\n",
    "# 글로벌 최소값 - 전체 함수 정의역에서 가장 낮은 값 (진짜 최적값)\n",
    "# 시각화 목적 - 손실 함수의 곡선 형태에서 최적화 알고리즘이 잘못된 지점에 머무를 수 있음을 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 시각화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Malgun Gothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. 손실 함수 정의\n",
    "def loss_function(x):\n",
    "  # 손실 함수 정의: 복잡한 최적화 문제를 시뮬레이션하기 위한 함수\n",
    "  # np.sin(3 * x): 여러 개의 로컬 최소값을 만들어내는 사인 함수\n",
    "  # 0.3 * x**2: 전체적으로 볼록한 형태를 만드는 이차항\n",
    "  # 이 두 함수를 더하면 비선형적인 복잡한 형태의 손실 함수가 됨\n",
    "  return np.sin(3 * x) + 0.3 * x**2\n",
    "\n",
    "# 2. x 범위 설정 및 손실 함수 값 계산\n",
    "x = np.linspace(-3, 3, 400) # -3 부터 3까지 400개의 균등한 점 생성\n",
    "y = loss_function(x) # 각 x에 대해 손실 함수 값 계산\n",
    "\n",
    "# 3. 로컬 최소값과 글로벌 최소값 위치 설정\n",
    "x_local_min = -1.1 # 로컬(지역) 최소값이 발생하는 x 위치 (직접 지정)\n",
    "y_local_min = loss_function(x_local_min) # 해당 위치에서의 손실 함수 값 계산\n",
    "x_global_min = 1.5 # 글로벌(전역) 최소값이 발생하는 x 위치 (직접 지정)\n",
    "y_global_min = loss_function(x_global_min) # 해당 위치에서의 손실 함수 값 계산\n",
    "\n",
    "# 4. 손실 함수 그래프 시각화\n",
    "plt.figure(figsize=(10, 6)) # 그래프 크기 설정\n",
    "plt.plot(x, y, label='손실 함수', color='blue') # 손실 함수 곡선 그리기\n",
    "plt.scatter(x_local_min, y_local_min, color='orange', s=100, label='로컬 최소값') # 로컬 최소값 점 표시 (주황색 원) \n",
    "plt.scatter(x_global_min, y_global_min, color='red', s=100, label='글로벌 최소값') # 글로벌 최소값 점 표시 (빨간색 원)\n",
    "plt.axhline(0, color='gray', linestyle='--', alpha=0.5) # y=0 기준선 (점선)\n",
    " \n",
    "# 5. 그래프 라벨 및 꾸미기\n",
    "plt.title('손실 함수에서 로컬 최소값과 글로벌 최소값') # 그래프 제목\n",
    "plt.xlabel('가중치 (Weight)') # x축 라벨\n",
    "plt.ylabel('손실값 (Loss)') # y축 라벨\n",
    "plt.legend() # 범례 표시\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 파란 선: 전체 손실 함수 그래프\n",
    "# 주황 점: 로컬 최소값 (근처에선 낮지만 전체적으로 더 낮은 지점이 있음)\n",
    "# 빨간 점: 글로벌 최소값 (전체에서 가장 낮은 지점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 회귀와 손실 최소화\n",
    "\n",
    "# 손실 함수는 평균 제곱 오차(MSE)를 사용합니다. \n",
    "# MSE = (1/n) * Σ(y_pred - y_true)² \n",
    "\n",
    "# MSE 손실을 줄이기 위한 경사하강법 적용 \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Malgun Gothic'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. 임의 데이터 생성 (선형 관계 + 약간의 노이즈) \n",
    "x = np.linspace(0, 10, 50)  # 0부터 10까지 균등한 간격으로 50개의 x값 생성\n",
    "# y_true는 기울기 3, 절편 5인 직선에 약간의 정규분포 노이즈를 추가한 값\n",
    "y_true = 3 * x + 5 + np.random.randn(50) # 실제 종속 변수 y값 (선형 관계 + 잡음)\n",
    "\n",
    "# 2. 선형 회귀 모델 초기화\n",
    "w, b = 0.0, 0.0 # 가중치(w), 편향(b) 모두 0으로 초기 설정\n",
    "lr = 0.01 # 학습률(Learning Rate), 파라미터 업데이트 보폭\n",
    "losses = [] # 각 에포크(epoch)별 손실(loss)을 저장할 리스트\n",
    "\n",
    "# 3. 경사 하강법을 이용한 모델 학습 (100번 반복)\n",
    "for epoch in range(100): # 100번 반복하며 파라미터를 점진적으로 최적화 \n",
    "  y_pred = w * x + b # 현재 가중치와 편향으로 예측값 계산 \n",
    "  error = y_pred - y_true # 오차 계산 (예측값 - 실제값) \n",
    "  loss = np.mean(error ** 2) # 손실 함수: 평균 제곱 오차 (MSE) \n",
    "  losses.append(loss) # 현재 손실 값을 리스트에 저장 \n",
    "\n",
    "  # 4. 손실 함수에 대한 기울기(gradient) 계산\n",
    "  dw = 2 * np.mean(error * x) # w에 대한 그래디언트 계산\n",
    "  db = 2 * np.mean(error) # b에 대한 그래디언트 계산\n",
    "\n",
    "  # 5. 파라미터 업데이트 (경사 하강법)\n",
    "  w -= lr * dw # w 업데이트: 손실을 줄이는 방향으로 이동 \n",
    "  b -= lr * db # b 업데이트: 손실을 줄이는 방향으로 이동 \n",
    " \n",
    "# 6. 손실 함수의 감소 과정을 시각화\n",
    "plt.plot(losses) # 각 에포크별 손실 값 시각화 \n",
    "plt.title(\"선형 회귀 손실 감소 과정 (MSE)\") # 그래프 제목 \n",
    "plt.xlabel(\"Epoch\") # x축: 학습 반복 횟수 \n",
    "plt.ylabel(\"Loss\") # y축: 평균 제곱 오차 \n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
