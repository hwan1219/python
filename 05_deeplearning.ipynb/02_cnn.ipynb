{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning 보충학습2\n",
    "# tensorflow.keras.datasets.mminst 학습\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Flatten, Input, Dense, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "import numpy as np\n",
    "\n",
    "# load_data()로 데이터셋을 로드\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 1) keras 내장 데이터셋 로드\n",
    "\n",
    "# 로드된 데이터셋 확인\n",
    "print(f\"train set: {x_train.shape}, {y_train.shape}\")\n",
    "print(f\"test set: {x_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# 데이터 시각화\n",
    "fig, axes = plt.subplots(3,5)\n",
    "fig.set_size_inches(8,5)\n",
    "\n",
    "for i in range(15):\n",
    "  ax = axes[i//5, i%5]\n",
    "  # // = 나눗셈 후 소수점을 버리고 몫만 남긴 값\n",
    "  # % = 나눗셈 후 남는 나머지\n",
    "  ax.imshow(x_train[i], cmap='gray')\n",
    "  ax.axis('off')\n",
    "  ax.set_title(str(y_train[i]))\n",
    "  \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#########################\n",
    "# 2)데이터 전처리\n",
    "\n",
    "# x_train 배열의 데이터 확인\n",
    "print(\"x_train 배열의 데이터 확인\")\n",
    "print(x_train[0, 10:15, 10:15]) # (순서, 행, 열)\n",
    "\n",
    "# 픽셀 값의 최소/최대 값 확인\n",
    "# min_val = np.min(x_train)\n",
    "# max_val = np.max(x_train)\n",
    "min_val = x_train.min()\n",
    "max_val = x_train.max()\n",
    "\n",
    "# 데이터 정규화\n",
    "x_train = x_train / x_train.max()\n",
    "\n",
    "# 정규화 후 최소/최대 값 확인\n",
    "print(f\"\\n[정규화 전] 최소값: {min_val}, 최대값: {max_val}\")\n",
    "print(f\"[정규화 후] 최소값: {x_train.min()}, 최대값: {x_train.max()}\")\n",
    "\n",
    "# test 셋에도 정규화 동일 적용\n",
    "x_test = x_test / x_train.max()\n",
    "\n",
    "# 변환 후 x_train 배열의 데이터 확인\n",
    "print(\"\\n변환 후 x_train 배열의 데이터 확인\")\n",
    "print(x_train[0, 10:15, 10:15])\n",
    "\n",
    "#########################\n",
    "# 3) Flatten 레이어 (N차원 → 1차원) : 평탄화(28*28=784)\n",
    "\n",
    "# reshape 함수 사용 평탄화\n",
    "print(f\"\\n변경 전 shape: {x_train.shape}\")\n",
    "print(f\"reshape로 이미지 축 평탄화 후 shape: {x_train.reshape(60000, -1).shape}\")\n",
    "# 60000은 샘플 수, 딥러닝을 하기 위해 쓰이는 이미지 관련 축만 평탄화 진행\n",
    "# 왜냐하면 딥러닝 모델의 입력 데이터 형식은 (샘플 수, 특징 수)여야 하기 때문\n",
    "\n",
    "# Flatten 레이어 사용 평탄화\n",
    "print(f\"\\n변경 전 shape: {x_train.shape}\")\n",
    "print(f\"Flatten 레이어로 이미지 축 평탄환 후 shape: {Flatten()(x_train).shape}\\n\")\n",
    "\n",
    "#########################\n",
    "# 4) 활성화 함수\n",
    "\n",
    "# Dense 레이어를 먼저 추가하고 활성화 함수를 별도로 적용한 경우\n",
    "example = Sequential([\n",
    "  Dense(128),\n",
    "  Activation('relu')\n",
    "])\n",
    "\n",
    "#########################\n",
    "# 5) 입력과 출력\n",
    "model = Sequential([\n",
    "  Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
    "  Flatten(),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(32, activation='relu'),\n",
    "  Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "#########################\n",
    "# 6) 손실함수\n",
    "\n",
    "# 방법1) 이진 분류 (출력 노드 개수 = 1, sigmoid 인 경우)\n",
    "example.compile(loss='binary_crossentropy')\n",
    "\n",
    "# 방법2) 다중분류 y가 원 핫 벡터인 경우\n",
    "example.compile(loss='categorical_crossentropy')\n",
    "\n",
    "# 방법3) y가 원 핫 벡터가 아닌 경우\n",
    "example.compile(loss='sparse_categorical_crossentropy')\n",
    "\n",
    "#########################\n",
    "# 7) 옵티마이저\n",
    "\n",
    "# 방법1) 클래스 인스턴스로 지정\n",
    "adam = Adam(learning_rate=0.001)\n",
    "example.compile(optimizer=adam)\n",
    "\n",
    "# 방법2) 문자열로 지정\n",
    "example.compile(optimizer='adam')\n",
    "\n",
    "#########################\n",
    "# 8) 평가지표\n",
    "\n",
    "# 방법1) 클래스 인스턴스로 지정\n",
    "acc = SparseCategoricalAccuracy()\n",
    "example.compile(\n",
    "  optimizer='adam',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=[acc]\n",
    ")\n",
    "\n",
    "# 방법2) 문자열로 지정\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#########################\n",
    "# 9) 훈련\n",
    "\n",
    "history = model.fit(\n",
    "  x_train, y_train,\n",
    "  validation_data=(x_test, y_test),\n",
    "  epochs=10\n",
    ")\n",
    "\n",
    "#########################\n",
    "# 10) 평가\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(\"\\n정확도:\", acc)\n",
    "\n",
    "#########################\n",
    "# 11) 예측\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "print(\"\\n0번 index에 대한 클래스 점수값\")\n",
    "print(f\"{predictions[0]}\")\n",
    "\n",
    "#########################\n",
    "# 12) n번 째 index에 대한 예측 클래스 출력\n",
    "\n",
    "# 0번 index에 대한 예측 클래스 출력\n",
    "print(f\"\\n0번 index에 대한 예측 클래스: {np.argmax(predictions[0])}\")\n",
    "\n",
    "# 첫10개 index에 대한 예측 클래스 출력\n",
    "print(f\"첫 10개 index에 대한 예측 클래스: {np.argmax(predictions[:10], axis=1)}\")\n",
    "\n",
    "#########################\n",
    "# 13) 데이터 시각화\n",
    "\n",
    "# y_true(정답), y_pred(예측값), predictions(x_test예측값), confidence(정확도)\n",
    "def get_one_result(i):\n",
    "  img = x_test[i]\n",
    "  y_true = y_test[i]\n",
    "  y_pred = np.argmax(predictions[i])\n",
    "  confidence = 100*np.max(predictions[i])\n",
    "  return img, y_true, y_pred, confidence\n",
    "\n",
    "fig, axes = plt.subplots(3, 5)\n",
    "fig.set_size_inches(12, 10)\n",
    "\n",
    "for i in range(15):\n",
    "  ax = axes[i//5, i%5]\n",
    "  \n",
    "  img, y_true, y_pred, confidence = get_one_result(i)\n",
    "  \n",
    "  # imshow 로 이미지 시각화\n",
    "  ax.imshow(img, cmap='gray') # 이미지\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "  ax.set_title(f\"True: {y_true}\")\n",
    "  ax.set_xlabel(f\"Prediction: {y_pred}\\nConfidence: ({confidence:.2f}%)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-2 실습\n",
    "\n",
    "# mnist 불러오기 + 시각화\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 불러오기\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 데이터 형태 출력\n",
    "print(\"학습용 이미지 크기:\", X_train.shape)\n",
    "print(\"테스트용 이미지 크기:\", X_test.shape)\n",
    "\n",
    "# 이미지 5개 출력\n",
    "plt.figure(figsize=(10,2))\n",
    "for i in range(5):\n",
    "  plt.subplot(1, 5, i+1)\n",
    "  plt.imshow(X_train[i], cmap='gray')\n",
    "  plt.title(f\"Label: {y_train[i]}\")\n",
    "  plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-3 일반 분류 딥러닝 & 이미지 분류 딥러닝 구조와 처리 방식\n",
    "\n",
    "# 1) 일반 분류\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# 데이터 불러오기\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 구성, 컴파일, 학습\n",
    "model = Sequential([\n",
    "  Input(shape=(X.shape[1],)),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "  X_train_scaled, y_train,\n",
    "  epochs=30,\n",
    "  batch_size=8,\n",
    "  validation_split=0.2,\n",
    "  verbose=1\n",
    ")\n",
    "\n",
    "# 정확도 시각화\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label=\"validation\")\n",
    "plt.title(\"Iris Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-3 일반 분류 딥러닝 & 이미지 분류 딥러닝 구조와 처리 방식\n",
    "\n",
    "# 2) 이미지 분류\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Input, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "model = Sequential([\n",
    "  Input(shape=(28, 28, 1)),\n",
    "  Conv2D(32, (3, 3), activation='relu'),\n",
    "  MaxPooling2D(),\n",
    "  Conv2D(64, (3, 3), activation='relu'),\n",
    "  MaxPooling2D(),\n",
    "  Flatten(),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['acc']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "  X_train, y_train,\n",
    "  epochs=5,\n",
    "  batch_size=64,\n",
    "  validation_split=0.1,\n",
    "  verbose=1\n",
    ")\n",
    "\n",
    "plt.plot(history.history['acc'], label=\"Train\")\n",
    "plt.plot(history.history['val_acc'], label=\"Validation\")\n",
    "plt.title(\"MNIST Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 예측값 일부 시각화\n",
    "pred = model.predict(X_test[:10])\n",
    "pred_classes = np.argmax(pred, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5)\n",
    "fig.set_size_inches(12, 4)\n",
    "\n",
    "for i in range(10):\n",
    "  ax = axes[i//5, i%5]\n",
    "  \n",
    "  ax.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "  ax.axis('off')\n",
    "  ax.set_title(f\"Pred: {pred_classes[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
