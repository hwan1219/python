{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP: IMDb 영화 리뷰 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMDb 영화 리뷰 데이터셋\n",
    "\n",
    "# 라이브러리 설정\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import json\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "SEED = 12\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 데이터셋 불러오기 및 크기 확인\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
    "# load_data(index_from=3) 값 추가시 디코딩 사전 인덱스가 3씩 더해짐\n",
    "# 그리고 0, 1, 2 위치의 인덱스에는 <PAD>, <START>, <UNK> 가 자동으로 생성되지만 3 위치의 <UNUSED> 는 생성되지 않음, 필요하다면 수동으로 추가해줘야함\n",
    "print(f\"X_train.shape: {X_train.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}\")\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "print(f\"y_test.shape: {y_test.shape}\")\n",
    "\n",
    "# 첫번째 리뷰 값(정수) 확인 + 길이 확인\n",
    "print(f\"\\n첫번째 리뷰 벡터 값들:\\n{X_train[0]}\")\n",
    "print(f\"첫번째 리뷰 길이(단어 개수): {len(X_train[0])}\\n\")\n",
    "\n",
    "# 디코딩 값 (딕셔너리 형태) [:10] 출력\n",
    "word_index = imdb.get_word_index()\n",
    "# for k, v in list(word_index.items())[:10]:\n",
    "#   print(f\"{k}: {v}\")\n",
    "print(json.dumps(dict(list(word_index.items())[:10]), indent=2, ensure_ascii=False))\n",
    "\n",
    "# 케라스 사전 전처리 및 벡터를 텍스트로 변환\n",
    "word_index = {k: (v+3) for k, v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "def decode_review(text_ids):\n",
    "  index_to_word = {v: i for i, v in word_index.items()}\n",
    "  return ' '.join([index_to_word.get(i, '?') for i in text_ids])\n",
    "\n",
    "# 첫번째 리뷰 디코딩\n",
    "encoded_review = X_train[0]\n",
    "decoded_review = decode_review(encoded_review)\n",
    "print(f\"\\n첫번째 리뷰 디코딩:\\n{decoded_review}\")\n",
    "\n",
    "# 첫번째 리뷰 정답 레이블\n",
    "print(f\"첫번째 리뷰 정답 레이블: {y_train[0]}\")\n",
    "\n",
    "# 각 리뷰의 단어 개수 분포\n",
    "review_length = [len(review) for review in X_train]\n",
    "sns.displot(review_length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. zero padding\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "X_train_pad = sequence.pad_sequences(X_train, maxlen=250)\n",
    "X_test_pad = sequence.pad_sequences(X_test, maxlen=250)\n",
    "\n",
    "print(X_train_pad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Word Embedding\n",
    "\n",
    "# Embedding: 단어 사이의 관계를 학습해서 서로 유사한 단어들끼리 벡터 공간상에서 비슷한 위치에 배치\n",
    "\n",
    "# 이는 희소한 One-Hot Encoding과 달리, 단어들을 연속적인 밀집(dense) 벡터 공간에 표현하는 방식\n",
    "\n",
    "# *희소하다: 대부분의 값이 0이고, 실제로 의미있는 값(0이 아닌 값)은 거의 없다는 것을 의미\n",
    "\n",
    "# 모델 정의\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_types = [SimpleRNN, LSTM, GRU]\n",
    "def build_model(model_type):\n",
    "  print(f\"{model_type.__name__} 모델 학습중...\")\n",
    "  model = Sequential()\n",
    "  \n",
    "  # Embedding\n",
    "  model.add(Embedding(input_dim=10000, output_dim=128, input_shape=(250,)))\n",
    "  \n",
    "  # model_type\n",
    "  model.add(model_type(64, return_sequences=True)) \n",
    "  model.add(model_type(64))\n",
    "  # return_sequences 값이 필요한 이유는 해당 파라미터의 기본값이 False 이고, 그 경우 timesteps(시간축) 차원이 사라진 2차원 형태로 값을 반환하기 때문에 더이상 3차원 input 형태를 요구하는 RNN 모델에 넣을 수 없게됨\n",
    "  \n",
    "  # Dense Classifier\n",
    "  model.add(Dense(32, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "  # Compile\n",
    "  model.compile(\n",
    "\t\toptimizer='adam',\n",
    "\t\tloss='binary_crossentropy',\n",
    "\t\tmetrics=['accuracy']\n",
    "\t)\n",
    "  model.summary()\n",
    "  \n",
    "  # fit (verbose = 2: epochs 단위 로그)\n",
    "  rnn_history = model.fit(\n",
    "\t\tX_train_pad, y_train,\n",
    "\t\tepochs = 10,\n",
    "\t\tbatch_size = 32,\n",
    "\t\tvalidation_split = 0.1,\n",
    "\t\tverbose = 2\n",
    "\t)\n",
    "  \n",
    "  return model, rnn_history\n",
    "\n",
    "for model_type in model_types:\n",
    "  _, rnn_history = build_model(model_type)\n",
    "  \n",
    "  def plot_metrics(history, model_type):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "    \n",
    "    # Loss: 손실 함수\n",
    "    axes[0].plot(range(1, 11), history.history['loss'][:10], label='Train')\n",
    "    axes[0].plot(range(1, 11), history.history['val_loss'][:10], label='Validation')\n",
    "    axes[0].set_title(f\"{model_type.__name__} Loss\")\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Accuracy: 예측 정확도\n",
    "    axes[1].plot(range(1, 11), history.history['accuracy'][:10], label='Train')\n",
    "    axes[1].plot(range(1, 11), history.history['val_accuracy'][:10], label='Validation')\n",
    "    axes[1].set_title(f\"{model_type.__name__} Accuracy\")\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.show()\n",
    "  \n",
    "  # 그래프 그리기\n",
    "  plot_metrics(rnn_history, model_type)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
