{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDb\n",
    "\n",
    "# IMDb 는 Internet Movie Database 의 약자로, 영화, TV 프로그램, 배우, 감독, 제작자 등에 대한 방대한 정보를 제공하는 세계 최대 규모의 영화 데이터베이스\n",
    "\n",
    "# IMDb 데이터셋 (머신러닝용)\n",
    "# TensorFlow/Keras 에서는 IMDb 데이터를 감성 분석용으로도 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-1 IMDb 실습1 (tensorflow datasets)\n",
    "# 데이터 불러오기\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "# 단어 수 제한 (상위 10,000개 단어만 사용)\n",
    "num_words = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = num_words)\n",
    "\n",
    "print(f\"훈련 샘플 수: {len(X_train)}\")\n",
    "print(f\"첫 번째 리뷰 (정수 인코딩): {X_train[0]}\")\n",
    "print(f\"첫 번째 리뷰의 라벨 (0: 부정, 1: 긍정): {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-2 IMDb 실습1 (tensorflow datasets)\n",
    "# 인코딩 ↔ 디코딩 프로그램 실습\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "# 1. 단어 수 제한 (상위10,000개 단어만 사용)\n",
    "num_words = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = num_words)\n",
    "\n",
    "# 2. 단어 사전 불러오기\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# 3. keras 사전은 특수 토큰 고려 X → 보정\n",
    "# load_data() 와 같은 학습에 쓰이는 데이터의 경우 자연어 처리 모델에서의 input_shape 값을 맞추고, 문장 시작과 같은 표시 등 학습에 도움을 주기 위한 토큰이 존재함\n",
    "# 하지만 해당 학습 데이터의 디코딩 값을 가지고 있는 get_word_index() 값은 해당 토큰을 가지고 있지 않기 때문에 위치 값을 맞춰주기 위해 똑같이 추가\n",
    "word_index = {k: (v+3) for k, v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# 4. 정수 → 단어 변환용 사전 생성성\n",
    "reverse_word_index = {val: key for key, val in word_index.items()}\n",
    "\n",
    "# 5. 인코딩된 리뷰 확인\n",
    "encoded_review = X_train[0]\n",
    "print(f\"인코딩된 리뷰 (앞 20단어만):\\n{encoded_review[:20]}\")\n",
    "\n",
    "# 6. 디코딩 함수 정의\n",
    "# 정수 → 문자열, 해당 인덱스가 딕셔너리에 없으면 ?\n",
    "def decode_review(text_ids):\n",
    "  return ' '.join([reverse_word_index.get(i, '?') for i in text_ids])\n",
    "\n",
    "# 7. 디코딩된 리뷰 보기\n",
    "decoded_review = decode_review(encoded_review)\n",
    "print(f\"\\n디코딩된 리뷰 (앞 20단어만):\\n{decoded_review.split()[:20]}\")\n",
    "\n",
    "# 8. 개별 인코딩/디코딩 확인\n",
    "print(\"\\n단어별 인코딩/디코딩 매핑 (앞 10개만):\")\n",
    "for i in range(10):\n",
    "  word = reverse_word_index.get(encoded_review[i], '?')\n",
    "  print(f\"{i+1:2d}: 인코딩 = {encoded_review[i]:5d} → 디코딩 = {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 IMDb 실습2\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from collections import Counter\n",
    "\n",
    "# 1. 상위 10,000개 단어만 사용\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# 2. 데이터 타입 및 크기 확인\n",
    "print(f\"X_train type: {type(X_train)}\")\n",
    "print(f\"X_train[0] type: {type(X_train[0])}\")\n",
    "print(f\"훈련 샘플 수: {X_train.shape}\")\n",
    "print(f\"테스트 샘플 수: {X_test.shape}\")\n",
    "\n",
    "# 3. 첫 번째 샘플 길이 확인\n",
    "print(f\"\\n첫 번째 샘플 리뷰 길이: {len(X_train[0])}\")\n",
    "\n",
    "# 4. 첫 번째 샘플 라벨 확인 + 라벨 분포\n",
    "print(f\"첫 번째 샘플 라벨 확인: {y_train[0]}\")\n",
    "print(f\"라벨 분포(훈련 샘플):\", {label: y_train.tolist().count(label) for label in set(y_train)})\n",
    "# print(f\"라벨 분포(훈련 샘플): {dict(Counter(y_train))}\")\n",
    "\n",
    "# 5. 정수 인코딩된 첫 번째 리뷰 확인 [:20]\n",
    "encoded_review = X_train[1]\n",
    "print(f\"\\n첫 번째 리뷰(정수 인코딩) [:20]:\\n{encoded_review[:20]}\")\n",
    "\n",
    "# 6. 단어 사전 불러오기\n",
    "word_index = imdb.get_word_index()\n",
    "print(f\"\\n단어 사전 길이: {len(word_index)}\")\n",
    "\n",
    "# 7. 사전 보정 (특수 토큰)\n",
    "word_index = {k: (v+3) for k, v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2 # unknown\n",
    "word_index[\"<UNUSED>\"] = 3 # unused(미사용)\n",
    "\n",
    "# 8. 정수 → 단어 변환용 사전 생성\n",
    "reverse_word_index = {v: k for k, v in word_index.items()}\n",
    "\n",
    "# 9. 디코딩 함수 정의\n",
    "def decode_review(text_ids):\n",
    "  return ' '.join([reverse_word_index.get(i, '?') for i in text_ids])\n",
    "\n",
    "# 10 디코딩된 첫 번째 리뷰 출력\n",
    "decoded_review = decode_review(encoded_review)\n",
    "print(f\"\\n디코딩된 리뷰:\\n{decoded_review}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
